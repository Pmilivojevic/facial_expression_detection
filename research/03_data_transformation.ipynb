{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/facial_expression_detection/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/facial_expression_detection'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    dataset_folder: Path\n",
    "    transformed_dataset: Path\n",
    "    dataset_labels_src: Path\n",
    "    dataset_labels: Path\n",
    "    params: dict\n",
    "    dataset_val_status: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.detmood.constant import *\n",
    "from src.detmood.utils.main_utils import create_directories, read_yaml\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_file_path = CONFIG_FILE_PATH,\n",
    "        params_file_path = PARAMS_FILE_PATH,\n",
    "        schema_file_path = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        self.schema = read_yaml(schema_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        dataset_val_status_file = self.config.data_validation.STATUS_FILE\n",
    "        \n",
    "        with open(dataset_val_status_file, 'r') as f:\n",
    "            status = f.read()\n",
    "        \n",
    "        status = bool(str.split(status)[-1])\n",
    "        \n",
    "        create_directories([config.transformed_dataset])\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            dataset_folder=config.dataset_folder,\n",
    "            transformed_dataset=config.transformed_dataset,\n",
    "            dataset_labels_src=config.dataset_labels_src,\n",
    "            dataset_labels=config.dataset_labels,\n",
    "            params=self.params,\n",
    "            dataset_val_status=status\n",
    "        )\n",
    "        \n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from src.detmood.constant.dataset_preparation import CustomImageDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import shutil\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def ungroup_folder_classes(self):\n",
    "        if not os.listdir(self.config.transformed_dataset):\n",
    "            for dir in os.listdir(self.config.dataset_folder):\n",
    "                os.makedirs(os.path.join(self.config.transformed_dataset, dir), exist_ok=True)\n",
    "                for class_dir in tqdm(os.listdir(os.path.join(self.config.dataset_folder, dir))):\n",
    "                    for img in tqdm(os.listdir(os.path.join(self.config.dataset_folder, dir, class_dir))):\n",
    "                        shutil.copy2(\n",
    "                            os.path.join(self.config.dataset_folder, dir, class_dir, img),\n",
    "                            os.path.join(self.config.transformed_dataset, dir)\n",
    "                        )\n",
    "            \n",
    "            shutil.copy2(self.config.dataset_labels_src, self.config.dataset_labels)\n",
    "    \n",
    "    def equalize_histogram(self, img):\n",
    "        img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        img_hsv[:,:,2] = cv2.equalizeHist(img_hsv[:,:,2])\n",
    "        img_eq = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        return img_eq\n",
    "    \n",
    "    def noise_reduction(self, img):\n",
    "        img_filt = cv2.medianBlur(\n",
    "            img,\n",
    "            self.config.params.transform.noise_reduction.median_filter_size\n",
    "        )\n",
    "        \n",
    "        return img_filt\n",
    "    \n",
    "    def labels_csv_transform(self):\n",
    "        labels_df = pd.read_csv(self.config.dataset_labels_src)\n",
    "        \n",
    "        for ind in labels_df.index:\n",
    "            labels_df.loc[ind, 'label'] = MOOD_DICT[labels_df.loc[ind, 'label']]\n",
    "        \n",
    "        labels_df.to_csv(self.config.dataset_labels, index=False)\n",
    "    \n",
    "    def dataset_folds_preparation(self):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((\n",
    "                self.config.params.model.img_in_size,\n",
    "                self.config.params.model.img_in_size\n",
    "            )),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.RandomAffine(translate=(0.1, 0.1), degrees=15),\n",
    "            transforms.RandomResizedCrop((224, 224), scale=(0.8, 1.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        dataset = CustomImageDataset(\n",
    "            self.config.dataset_labels,\n",
    "            self.config.dataset_folder,\n",
    "            self.config.params.model.data_aug_size,\n",
    "            transform=transform\n",
    "        )\n",
    "        \n",
    "        skf = StratifiedKFold(\n",
    "            n_splits=self.config.params.model.num_folds,\n",
    "            shuffle=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        splits = skf.split(dataset.balanced_frame, dataset.balanced_frame['label'])\n",
    "        \n",
    "        return dataset, splits\n",
    "    \n",
    "    def transformation_compose(self):\n",
    "        if self.config.dataset_val_status:\n",
    "            # if len(os.listdir(self.config.dataset_folder)) == 0:\n",
    "            self.ungroup_folder_classes()\n",
    "            # for img_name in tqdm(os.listdir(self.config.transformed_dataset)):\n",
    "            for img_name in tqdm(os.listdir(os.path.join(self.config.transformed_dataset, 'train'))):\n",
    "                img = cv2.imread(os.path.join(self.config.transformed_dataset, 'train', img_name))\n",
    "                img_eq = self.equalize_histogram(img)\n",
    "                img_filt = self.noise_reduction(img_eq)\n",
    "                \n",
    "                cv2.imwrite(os.path.join(self.config.transformed_dataset, 'train', img_name), img_filt)\n",
    "            \n",
    "            # self.labels_csv_transform()\n",
    "\n",
    "            \n",
    "            dataset, splits = self.dataset_folds_preparation()\n",
    "            \n",
    "            return dataset, splits\n",
    "        else:\n",
    "            print(\"Dataset is not valid!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-27 20:52:38,877: INFO: main_utils: created directory at: artifacts]\n",
      "[2024-11-27 20:52:38,879: INFO: main_utils: created directory at: artifacts/data_transformation/DATASET]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 7556.64it/s]\n",
      "100%|██████████| 74/74 [00:00<00:00, 7404.24it/s]\n",
      "100%|██████████| 1185/1185 [00:00<00:00, 6791.07it/s]\n",
      "100%|██████████| 680/680 [00:00<00:00, 8054.65it/s]\n",
      "100%|██████████| 160/160 [00:00<00:00, 8075.77it/s]\n",
      "100%|██████████| 478/478 [00:00<00:00, 7701.08it/s]\n",
      "100%|██████████| 162/162 [00:00<00:00, 7976.86it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 15.80it/s]\n",
      "100%|██████████| 1290/1290 [00:00<00:00, 9076.08it/s]\n",
      "100%|██████████| 281/281 [00:00<00:00, 6837.61it/s]\n",
      "100%|██████████| 4772/4772 [00:00<00:00, 8668.48it/s]\n",
      "100%|██████████| 2524/2524 [00:00<00:00, 8361.49it/s]\n",
      "100%|██████████| 717/717 [00:00<00:00, 7684.82it/s]\n",
      "100%|██████████| 1982/1982 [00:00<00:00, 7473.11it/s]\n",
      "100%|██████████| 705/705 [00:00<00:00, 7435.89it/s]\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.59it/s]\n",
      "100%|██████████| 12271/12271 [00:05<00:00, 2191.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(5): np.int64(14316), np.int64(4): np.int64(14316), np.int64(1): np.int64(14316), np.int64(6): np.int64(14316), np.int64(2): np.int64(14316), np.int64(3): np.int64(14316), np.int64(7): np.int64(14316)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    dataset, splits = data_transformation.transformation_compose()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100212"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.balanced_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
